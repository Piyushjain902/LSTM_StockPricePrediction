ğŸ’¹ Stock Market Prediction using LSTM & ML Models ğŸ“ˆ
<p align="center"> <img src="stockmarket.png" alt="Stock Market Prediction" /> </p> <p align="center"> A robust time-series forecasting project leveraging Deep Learning and Machine Learning techniques to predict stock market trends. </p>
ğŸ“Š Project Overview
This repository presents a comprehensive pipeline for stock market prediction using both deep learning and traditional machine learning models. The project focuses on forecasting the closing price of Infosys (INFY) stock, comparing model performances, and visualizing results.

Key Objectives:

Explore and preprocess historical stock data.

Build, train, and evaluate multiple regression models.

Compare classical ML models with an LSTM deep learning approach.

Forecast future stock prices and visualize predictions.

ğŸ—‚ï¸ Dataset
Source: Historical daily prices for Infosys (INFY) from 1996 to 2021.

Features Used: Open, High, Low, Close

Target: Next day's closing price (Target column engineered as shifted Close).

ğŸ§  Models Implemented
1. Linear Regression
Simple, interpretable baseline for regression.

Trained on scaled features.

2. K-Nearest Neighbors (KNN) Regression
Captures local patterns in the data.

Used with 4 neighbors.

3. Support Vector Regression (SVR)
RBF kernel for non-linear relationships.

Tuned for regression; performance compared with other models.

4. Decision Tree Regression
Handles non-linearity and feature interactions.

Used as a classical ML benchmark.

5. Long Short-Term Memory (LSTM) Neural Network
Deep learning model designed for sequential/time-series data.

Uses 60-day rolling window as input sequence.

Architecture: Two LSTM layers (64 and 32 units), Dropout for regularization, Dense output.

Trained with early stopping to prevent overfitting.

ğŸ“ˆ Exploratory Data Analysis
Visualization: Trends of Open, High, Low, Close over time.

Correlation Analysis: Heatmap to identify feature redundancy and multicollinearity.

Feature Engineering: Removal of irrelevant columns, creation of Target as next-day close.

ğŸ› ï¸ Data Preprocessing
Train/Test Split: 80/20, preserving temporal order (no shuffling).

Scaling: StandardScaler for ML models; MinMaxScaler for LSTM and Close price normalization.

Sequence Preparation: For LSTM, 60-day rolling window sequences with 4 features.

ğŸ”§ Model Training & Evaluation
Classical Regression Models
Model	RMSE	MAE	RÂ² Score
Linear Regression	25.90	12.94	0.9871
KNN Regression	29.32	16.77	0.9835
SVR	723.52	684.16	-9.0585
Decision Tree	37.61	22.99	0.9728
Linear Regression provided the best classical ML performance. 

LSTM Model
Architecture: 2 LSTM layers (64, 32 units), Dropout to reduce overfitting, Dense output.

Training: Early stopping on validation loss.

Test Performance:

RMSE: 46.63

MAE: 29.06

RÂ² Score: 0.9579

Visualization: Plots of learning curves and predicted vs. actual closing prices.

<p align="center"> <img src="predictionVsActual.png" alt="Prediction Vs Actual" /> </p> <p align="center">

ğŸ”® Future Forecasting
Method: The trained LSTM model predicts the next 30 days of closing prices using a rolling window approach.

<p align="center"> <img src="next30daysPrediction.png" alt="Stock Market Prediction" /> </p> <p align="center">

Comparison: Actual vs. predicted close prices for the forecast window are tabulated for direct comparison.

Day	Actual Close (â‚¹)	Predicted Close (â‚¹)
Day	Actual Close (â‚¹)	Predicted Close (â‚¹)
0	1	1560.75	1565.2806
1	2	1562.20	1572.5125
2	3	1578.95	1577.8279
3	4	1562.00	1581.6860
4	5	1547.85	1584.4603
5	6	1533.75	1586.4436
6	7	1536.30	1587.8579
7	8	1538.10	1588.8682
8	9	1555.45	1589.5945
9	10	1549.60	1590.1223
10	11	1537.55	1590.5123
11	12	1538.00	1590.8062
12	13	1561.40	1591.0328
13	14	1585.05	1591.2118
14	15	1611.65	1591.3566
15	16	1609.30	1591.4758
16	17	1607.60	1591.5758
17	18	1600.10	1591.6605
18	19	1606.15	1591.7330
19	20	1634.75	1591.7953
20	21	1688.65	1591.8488
21	22	1679.90	1591.8949
22	23	1660.00	1591.9343
23	24	1660.65	1591.9684
24	25	1667.45	1591.9973
25	26	1680.00	1592.0220
26	27	1684.00	1592.0430
27	28	1696.50	1592.0607
28	29	1722.50	1592.0757
29	30	1691.30	1592.0885

The LSTM model captures the overall trend but tends to underpredict sharp upward movements in the actual price.

ğŸ“ Folder Structure
text
â”œâ”€â”€ LSTM_StockPricePrediction.ipynb   # Jupyter notebook with full workflow
â”œâ”€â”€ stockmarket.png                   # Project banner image
â”œâ”€â”€ README.md                         # Project documentation
â”œâ”€â”€ data/
â”‚   â””â”€â”€ INFY.csv                      # Infosys historical stock data
ğŸ› ï¸ Tech Stack
Python 3.11

Jupyter Notebook

NumPy, Pandas â€“ Data processing

Matplotlib, Seaborn â€“ Visualization

Scikit-learn â€“ ML models, preprocessing, metrics

TensorFlow/Keras â€“ Deep learning (LSTM)

ğŸš€ How to Run
Clone the repository and place the dataset in the data/ folder.

Open LSTM_StockPricePrediction.ipynb in Jupyter Notebook.

Run all cells to reproduce the analysis, training, evaluation, and forecasting.

ğŸ“¢ Results & Insights
Linear Regression performed best among classical models.

LSTM provided robust trend prediction and smooth forecasts, though it may lag on sharp price spikes.

SVR was not effective for this dataset without further tuning.

ğŸ“¬ Contact
For questions or suggestions, feel free to open an issue or contact the maintainer.